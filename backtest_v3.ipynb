{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/sunkism/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "ipykernel_launcher:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "백테스트 완료!!\n",
      "종목별가격 로드 : 0.14502215385437012 sec\n",
      "수익률계산 및 비중 초기화 : 0.1700139045715332 sec\n",
      "지수 백테스트 : 0.025710105895996094 sec\n",
      "결과데이터변환 : 0.010991096496582031 sec\n",
      "총 소요시간 : 0.35173726081848145 sec\n"
     ]
    }
   ],
   "source": [
    "# 산출속도 향상을 위해 dataframe을 dict or list 구조로 변경하여 처리함\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import json\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "#입력포맷\n",
    "my_input = {'start_date' : '2018-01-01',\n",
    "            'init_index' : 1000,\n",
    "            'init_amt' : 1000000,\n",
    "            'portfolio' : ['069500','261220','332940','371450','HERO','SPY'],\n",
    "            'rebalancing' : {\n",
    "                '2018-01-01' : [15,15,20,25,15,10],\n",
    "                '2019-01-01' : [15,15,20,25,15,10],\n",
    "                '2020-01-01' : [15,15,20,25,15,10],\n",
    "                '2021-01-01' : [15,15,20,25,15,10]}                \n",
    "            }\n",
    "\n",
    "prc_list = []\n",
    "for item in my_input['portfolio'] :\n",
    "    # excel 파일 읽기\n",
    "    infile = 'price_' + item + '.xlsx'\n",
    "    df = pd.read_excel(infile,dtype='unicode')\n",
    "    \n",
    "    # timeseries로 변환\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # 컬럼명 'PRICE'를 symbol code로 바꾼다\n",
    "    df.rename(columns={'PRICE':item},inplace=True)\n",
    "    df[item] = df[item].astype(float)\n",
    "    prc_list.append(df)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# 벤치마크 설정\n",
    "infile = \"benchmark.xlsx\"\n",
    "tmp_bm_df = pd.read_excel(infile,dtype='unicode')\n",
    "    \n",
    "# timeseries로 변환\n",
    "tmp_bm_df.set_index('DATE', inplace=True)\n",
    "tmp_bm_df.index = pd.to_datetime(tmp_bm_df.index)\n",
    "# 컬럼명 'benchmark'으로 변환\n",
    "tmp_bm_df.rename(columns={'PRICE':'benchmark'},inplace=True)\n",
    "tmp_bm_df['benchmark'] = tmp_bm_df['benchmark'].astype(float)\n",
    "\n",
    "# 벤치마크를 prc_list에 넣는 이유는, 날짜별로 발생할 수 있는 결측치를 없애기 위해서임.\n",
    "# 예를들어 한국종목으로 포트폴리오를 구성하고, BM을 S&P 500으로 설정한다면, 분석시 데이터 처리가 번거로워진다\n",
    "prc_list.append(tmp_bm_df)\n",
    "\n",
    "\n",
    "# 무위험이자율 설정\n",
    "infile = \"riskfree.xlsx\"\n",
    "tmp_rskfre_df = pd.read_excel(infile,dtype='unicode')\n",
    "# timeseries로 변환\n",
    "tmp_rskfre_df.set_index('DATE', inplace=True)\n",
    "tmp_rskfre_df.index = pd.to_datetime(tmp_rskfre_df.index)\n",
    "# 컬럼명 'BM'으로 변환\n",
    "tmp_rskfre_df.rename(columns={'CD91':'riskfree'},inplace=True)\n",
    "tmp_rskfre_df['riskfree'] = tmp_rskfre_df['riskfree'].astype(float)\n",
    "\n",
    "prc_list.append(tmp_rskfre_df)\n",
    "\n",
    "# 마켓지표 설정\n",
    "infile = \"kospi.xlsx\"\n",
    "tmp_kospi_df = pd.read_excel(infile,dtype='unicode')\n",
    "# timeseries로 변환\n",
    "tmp_kospi_df.set_index('DATE', inplace=True)\n",
    "tmp_kospi_df.index = pd.to_datetime(tmp_kospi_df.index)\n",
    "# 컬럼명 'BM'으로 변환\n",
    "tmp_kospi_df.rename(columns={'PRICE':'kospi'},inplace=True)\n",
    "tmp_kospi_df['kospi'] = tmp_kospi_df['kospi'].astype(float)\n",
    "\n",
    "prc_list.append(tmp_kospi_df)\n",
    "\n",
    "\n",
    "\n",
    "# 하나의 DATAFRAME으로 합친다\n",
    "prc_df = pd.concat(prc_list,join='outer',axis=1)\n",
    "\n",
    "# 결측값(N/A)을 처리한다. method='pad'를 넣으면 N/A부분을 직전값으로 대체한다. \n",
    "# 상장이 늦게된종목의 경우 앞에서 부터 계속 N/A이므로 결측값의 대체가 어렵다 (나중에 0으로 바꿀지 고민해보자)\n",
    "prc_df.fillna(method='pad',inplace=True)\n",
    "\n",
    "# prc_df에서 [벤치마크/무위험이자율/KOSPI]와 포트폴리오 시계열을 분리한다\n",
    "#bm_series = prc_df['BM']  # Series 로 변환됨\n",
    "#bm_df = bm_series.to_frame(name='BM') # Datafram으로 바꾸고...\n",
    "new_df = prc_df[['benchmark','riskfree','kospi']]\n",
    "\n",
    "#만약 벤치마크 앞쪽데이터가 없을 경우엔 데이터가 있는 날짜의 데이터로 채운다.\n",
    "#시계열 분석시 직전 데이터로 채워야하나(method='pad'), 힘빼지말자...\n",
    "new_df.fillna(method='bfill',inplace=True)\n",
    "#벤치마크를 지수와 같은 스케일(첫시작을 1000)로 변환한다.\n",
    "ratio = my_input['init_index'] / new_df.iloc[0].loc['benchmark']\n",
    "new_df['BM1000'] = new_df['benchmark'] * ratio\n",
    "\n",
    "\n",
    "# 포트폴리오 시계열에서 BM 삭제\n",
    "prc_df.drop(['benchmark','riskfree','kospi'],axis=1,inplace=True)\n",
    "\n",
    "# EXCEL에 쓰기 \n",
    "# df.index = df.index.date은 concat 후에 변환하자. concat 전에 하면, 늦게 상장한 종목부터 합쳐진다\n",
    "# prc_df.index = prc_df.index.date\n",
    "\n",
    "# 수익률 구하기\n",
    "rtn_df = prc_df.pct_change()\n",
    "rtn_df.fillna(0,inplace=True) # 첫날의 수익률은 0으로 SET\n",
    "\n",
    "\n",
    "# 초기비중설정 (리벨런싱 반영)\n",
    "init_wght_df = pd.DataFrame(data=None, columns=rtn_df.columns, index=rtn_df.index)\n",
    "for key, value in my_input['rebalancing'].items() :\n",
    "    myindex = init_wght_df.index[init_wght_df.index.get_loc(key,method='bfill')]\n",
    "    init_wght_df.loc[myindex] = [ x / 100 for x in value ]\n",
    "    \n",
    "t2 = time.time()\n",
    "\n",
    "# 지수 백테스팅\n",
    "\n",
    "## 초기값 세팅\n",
    "my_index = my_input['init_index']\n",
    "my_deposit = my_input['init_amt']\n",
    "\n",
    "tot_rtn_list = []\n",
    "my_index_list = []\n",
    "my_deposit_list = []\n",
    "\n",
    "##빠른 loop처리를 위해 dict로 변환 후 iteration 작업 (df -> dict -> list)\n",
    "rtn_dict = rtn_df.to_dict('split')\n",
    "rtns = rtn_dict['data']\n",
    "\n",
    "wght_dict = init_wght_df.to_dict('split')\n",
    "wghts = wght_dict['data']\n",
    "\n",
    "## 지수 계산 시작\n",
    "for i in range(0,len(rtns)) :\n",
    "    tot_rtn = sum([ x*y for (x,y) in zip(rtns[i], wghts[i]) ]) / sum(wghts[i])\n",
    "    my_index = my_index * (1+tot_rtn)\n",
    "    my_deposit = my_deposit * (1+tot_rtn)\n",
    "    \n",
    "    tot_rtn_list.append(tot_rtn)\n",
    "    my_index_list.append(my_index)\n",
    "    my_deposit_list.append(my_deposit)\n",
    "    \n",
    "    # 다음 wghts 값이 미리설정되지 않았다면, 수익률을 반영한 비중을 계산한다. 즉, 리벨런싱은 skip\n",
    "    if i < ( len(rtns) -1 ) :\n",
    "        if  np.isnan(wghts[i+1]).any() :\n",
    "            wghts[i+1] = [ (1+x)*y for (x,y) in zip(rtns[i],wghts[i])]\n",
    "        #else :\n",
    "        #    print (wghts[i+1])\n",
    "\n",
    "index_df = pd.DataFrame({'backtest':my_index_list, 'rtn':tot_rtn_list, 'deposit':my_deposit_list},index=rtn_df.index)\n",
    "weight_df =  pd.DataFrame(data=wghts, columns=init_wght_df.columns, index=init_wght_df.index)\n",
    "t3 = time.time()\n",
    "\n",
    "# 시계열분석을 위해, 산출된 지수값과 벤치마크, 무위험이자율, kospi지수를 json형태로 변환한다.\n",
    "\n",
    "result_df = pd.concat([index_df,new_df],join='outer',axis=1)\n",
    "result_df.reset_index(inplace=True)\n",
    "result_df['DATE'] = result_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "result_df.to_json('result.json',orient='records')\n",
    "t4 = time.time()\n",
    "\n",
    "print(\"백테스트 완료!!\")\n",
    "\n",
    "elapsed_time = t1 - t0\n",
    "print(f\"종목별가격 로드 : {elapsed_time} sec\")\n",
    "\n",
    "elapsed_time = t2 - t1\n",
    "print(f\"수익률계산 및 비중 초기화 : {elapsed_time} sec\")\n",
    "\n",
    "elapsed_time = t3 - t2\n",
    "print(f\"지수 백테스트 : {elapsed_time} sec\")\n",
    "\n",
    "elapsed_time = t4 - t3\n",
    "print(f\"결과데이터변환 : {elapsed_time} sec\")\n",
    "\n",
    "\n",
    "elapsed_time = t4 - t0\n",
    "print(f\"총 소요시간 : {elapsed_time} sec\")\n",
    "\n",
    "\n",
    "index_df.to_excel(\"myindex_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final Balance :  1382387\nCAGR :  10.11343 %\nStdev :  12.10452 %\nBest Year ( 2020 ) :  20.0979 %\nWorst Year ( 2021 ) :  7.55422 %\nMDD :  -26.74341 %\nSharpe Ratio :  0.70862\nSortino Ratio :  0.97904\nKorean MKT Correlation :  0.76477\nArithmetic Mean (daily) :  0.04116 %\nArithmetic Mean (annualized) :  10.92562 %\nGeometric Mean (daily) :  0.03824 %\nGeometric Mean (annualized) :  10.11343 %\nVolatility (daily) :  0.76251 %\nVolatility (annualized) :  12.10452 %\nDownside Deviation (daily) :  0.55189 %\nMDD :  -26.74341 %\nKorean MKT Correlation :  0.76477\nBeta(vs market) :  0.4745\nAlpha(vs market, annualized) :  6.36482 %\nR2(vs market) :  58.48767 %\nBeta(vs benchmark) :  0.46183\nAlpha(vs benchmark, annualized) :  6.03074 %\nR2(vs benchmark) :  59.38455 %\nSharpe Ratio :  0.70862\nSortino Ratio :  0.97904\nSkewness :  -0.90622\nExcess Kurtosis :  15.34846\nHistorical VaR(5%) :  -0.90545 %\nAnalytical VaR(5%) :  -1.21307 %\nConditional VaR(5%) :  -1.85039 %\n==================================================\nFinal Balance :  1382387\nCAGR :  8.04527 %\nStdev :  20.19767 %\nBest Year ( 2020 ) :  32.51523 %\nWorst Year ( 2021 ) :  8.9933 %\nMDD :  -41.05014 %\nSharpe Ratio :  0.39517\nSortino Ratio :  0.56251\nKorean MKT Correlation :  0.99238\nArithmetic Mean (daily) :  0.03879 %\nArithmetic Mean (annualized) :  10.26694 %\nGeometric Mean (daily) :  0.03071 %\nGeometric Mean (annualized) :  8.04527 %\nVolatility (daily) :  1.27233 %\nVolatility (annualized) :  20.19767 %\nDownside Deviation (daily) :  0.89383 %\nMDD :  -41.05014 %\nKorean MKT Correlation :  0.99238\nBeta(vs market) :  1.02739\nAlpha(vs market, annualized) :  0.68402 %\nR2(vs market) :  98.48161 %\nBeta(vs benchmark) :  1.0\nAlpha(vs benchmark, annualized) :  0.0 %\nR2(vs benchmark) :  100.0 %\nSharpe Ratio :  0.39517\nSortino Ratio :  0.56251\nSkewness :  0.12003\nExcess Kurtosis :  7.61168\nHistorical VaR(5%) :  -1.90691 %\nAnalytical VaR(5%) :  -2.05401 %\nConditional VaR(5%) :  -3.0227 %\n==================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "import simplejson\n",
    "\n",
    "def init_analyze(input_df) :\n",
    "    df = input_df.copy()\n",
    "    df.rename(columns={'DATE':'date'},inplace=True)\n",
    "    df.set_index(['date'],inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['prev'] = df['backtest'].shift(1)\n",
    "    df['kospi_rtn'] = df['kospi'].pct_change()\n",
    "    df['bm_prev'] = df['benchmark'].shift(1)\n",
    "    df['bm_rtn'] = df['benchmark'].pct_change()\n",
    "    df['riskfree'] = df['riskfree'] / 100\n",
    "\n",
    "    # 시계열 분석 편의를 위해 첫데이터를 날린다.\n",
    "    df = df.iloc[1:]\n",
    "    return df\n",
    "\n",
    "def init_result():\n",
    "    return {\n",
    "    'final_balance' : 0,\n",
    "    'cagr' : 0,\n",
    "    'stdev' : 0,\n",
    "    'annlzd_stdev' : 0,\n",
    "    'arith_mean' : 0,\n",
    "    'annlzd_arith_mean' : 0,\n",
    "    'geo_mean' : 0,\n",
    "    'annlzd_geo_mean' : 0,\n",
    "    'vol' : 0,\n",
    "    'annlzd_vol' : 0,\n",
    "    'hist_var' : 0,\n",
    "    'anal_var' : 0,\n",
    "    'c_var' : 0,\n",
    "    'best_y' : {'year' : 0, 'rtn' : 0},\n",
    "    'worst_y' : {'year' : 0, 'rtn' : 0},\n",
    "    'mdd' : 0,\n",
    "    'skewness' : 0,\n",
    "    'kurtosis' : 0,\n",
    "    'sharpe_rto' : 0,\n",
    "    'sortino_rto' : 0,\n",
    "    'down_dev' : 0,\n",
    "    'vs_market' : {'beta' : 0, 'alpha' : 0, 'r2' : 0, 'corr' : 0},\n",
    "    'vs_benchmark' : {'beta' : 0, 'alpha' : 0, 'r2' : 0, 'corr' : 0}\n",
    "    }\n",
    "\n",
    "def analyze_data(df):\n",
    "    \n",
    "    result = init_result()\n",
    "    \n",
    "    NUM_OF_DAYS = 252\n",
    "    \n",
    "    # 1. Final Balance\n",
    "    #initial_balance = 1000000\n",
    "    #final_balance = initial_balance * df['backtest'].iloc[-1] / df['prev'].iloc[0]\n",
    "    result['final_balance'] = df['deposit'].iloc[-1]\n",
    "\n",
    "    # 2. CAGR (2000-12월 종가부터, 2019-04월 종가까지 기간을 잡는다.)\n",
    "    year = df['backtest'].count() / NUM_OF_DAYS\n",
    "    # 2000-12월 종가는 2001-1월의 전일가격을 사용\n",
    "    CAGR = ( df.iloc[-1]['backtest'] / df.iloc[0]['prev'] )**(1/year) - 1\n",
    "    result['cagr'] = CAGR\n",
    "\n",
    "    # 3. Stdev (Annualized standard deviation of monthly returns)\n",
    "    stdev = df['rtn'].std()\n",
    "    result['stdev'] = stdev\n",
    "    # 연간화를 위해 루트 NUM_OF_DAYS 를 곱한다.\n",
    "    annlzd_stdev = stdev*(NUM_OF_DAYS**0.5)\n",
    "    result['annlzd_stdev'] = annlzd_stdev\n",
    "    result['vol'] = stdev\n",
    "    result['annlzd_vol'] = annlzd_stdev\n",
    "\n",
    "    # 4. Arithmetic Mean (monthly). \n",
    "    arith_mean = df['rtn'].mean()\n",
    "    result['arith_mean'] = arith_mean\n",
    "\n",
    "    # 5. Arithmetic Mean (annualized).\n",
    "    annualized_arith_mean = (1 + arith_mean) ** NUM_OF_DAYS - 1\n",
    "    result['annlzd_arith_mean'] = annualized_arith_mean\n",
    "\n",
    "    # 6. Geometric Mean, scipy 의 gmean사용\n",
    "    # 수익률의 기하평균은 각 수익률에 1을 더한후 루트를 적용, 이후에 1을 뺀다\n",
    "    # monthly_rtn의 모든 컬럼값에 1을 더한다\n",
    "    df['rtn_1'] = df['rtn'] + 1\n",
    "    # gmean은 list형의 인자를 받는다\n",
    "    geo_mean = gmean(df['rtn_1'].tolist()) - 1\n",
    "    result['geo_mean'] = geo_mean\n",
    "\n",
    "    # 7. Geometric Mean(annualized)\n",
    "    annualized_geo_mean = ( 1 + geo_mean) ** NUM_OF_DAYS - 1\n",
    "    result['annlzd_geo_mean'] = annualized_geo_mean\n",
    "\n",
    "    # 8. Volatility (monthly) . 변동성은 표준편차를 의미\n",
    "    #stdev = m_idx['rtn'].std() \n",
    "    #result['stdev'] = stdev\n",
    "\n",
    "    # 9. Volatility (annualized). 3에서 구한 Stdev와 같은 값이다\n",
    "    # 연간화를 위해 루트12 를 곱한다.\n",
    "    #stdev = stdev*(12**0.5)\n",
    "\n",
    "    # 10. VaR\n",
    "    # 10.1 Historical VaR \n",
    "    # exclusive quantile을 자체 구현\n",
    "    def quantile_exc(df2, q):\n",
    "        list_sorted = sorted(df2) # sorted()는 list형의 결과를 리턴한다\n",
    "        rank = q * (len(list_sorted) + 1) - 1\n",
    "        #print (\"q_exc : \", rank)\n",
    "        #assert rank > 0, 'quantile is too small'\n",
    "        if rank < 0 :\n",
    "            print ('quantile is too small')\n",
    "            return 0\n",
    "        rank_l = int(rank)\n",
    "        return list_sorted[rank_l] + (list_sorted[rank_l + 1] - \n",
    "                                      list_sorted[rank_l]) * (rank - rank_l)\n",
    "\n",
    "    historical_var_95 = quantile_exc(df['rtn'], 0.05)\n",
    "    if (historical_var_95 == 0) :\n",
    "        historical_var_95 = df['rtn'].quantile(0.05)\n",
    "    result['hist_var'] = historical_var_95\n",
    "\n",
    "    # 10.2 Analytical VaR\n",
    "    mean = df['rtn'].mean()\n",
    "    stdev = df['rtn'].std()\n",
    "    analytical_var_95 = norm.ppf(0.05, mean, stdev)\n",
    "    result['anal_var'] = analytical_var_95\n",
    "\n",
    "    # 10.3 Conditional VaR\n",
    "    # 자체구현\n",
    "    def conditional_var(df3, q):\n",
    "        list_sorted = sorted(df3)\n",
    "        rank = q * len(list_sorted) \n",
    "        rank_l = int(rank)\n",
    "\n",
    "        sum_rtn = 0\n",
    "        sum_rtn = sum(i for i in list_sorted[0:rank_l])\n",
    "\n",
    "        return 1 / rank * sum_rtn\n",
    "\n",
    "    cvar_95 = conditional_var(df['rtn'], 0.05)\n",
    "    result['c_var'] = cvar_95\n",
    "\n",
    "    # 11. Best Year / Worst Year\n",
    "    # 년단위 데이터로 resamplingn\n",
    "    y_idx = df.resample(rule='Y').last()\n",
    "    y_idx['rtn'] = y_idx['backtest'].pct_change()\n",
    "    if len(y_idx) == 1 :\n",
    "        min_val = df['backtest'].iloc[-1] / df['prev'].iloc[0] - 1\n",
    "        min_idx = df['backtest'].idxmin()\n",
    "        max_val = df['backtest'].iloc[-1] / df['prev'].iloc[0] - 1\n",
    "        max_idx = df['backtest'].idxmax()     \n",
    "    else :\n",
    "        min_val = y_idx['rtn'].min()\n",
    "        min_idx = y_idx['rtn'].idxmin()\n",
    "        max_val = y_idx['rtn'].max()\n",
    "        max_idx = y_idx['rtn'].idxmax()\n",
    "    result['best_y']['year'] = max_idx.year\n",
    "    result['best_y']['rtn'] = max_val\n",
    "    result['worst_y']['year'] = min_idx.year\n",
    "    result['worst_y']['rtn'] = min_val\n",
    "\n",
    "    # 12. MDD, \n",
    "    # - step1.지수의 수익률을 일별 누적(1+r을 계속곱해나감). \n",
    "    # - step2. 누적수익률에 대한 MAX를 일별로 기록\n",
    "    # - step3. 일별로 누적수익률과 MAX수익률 간의 차이((CUM - MAX) / MAX) 가 가장 큰 것을 잡는다.\n",
    "\n",
    "    #  등락률에 1을 더한다\n",
    "    df['rtn_1'] = df['rtn'] + 1\n",
    "\n",
    "    # 누적수익률계산\n",
    "    df['cum'] = df['rtn_1'].cumprod()\n",
    "\n",
    "    # 누적수익률중 최고값\n",
    "    df['high'] = df['cum'].cummax()\n",
    "\n",
    "    # drawdown 계산\n",
    "    df['drawdown'] = (df['cum'] - df['high'])/df['high']\n",
    "    MDD = df['drawdown'].min()\n",
    "    result['mdd'] = MDD\n",
    "\n",
    "    # 13. Skewness\n",
    "    skewness = df['rtn'].skew()\n",
    "    result['skewness'] = skewness\n",
    "\n",
    "    # 14. Excess Kurtosis\n",
    "    ex_kurtosis = df['rtn'].kurtosis()\n",
    "    result['kurtosis'] = ex_kurtosis\n",
    "\n",
    "    # 15. Ratio\n",
    "    # https://www.quantnews.com/performance-metrics-sharpe-ratio-sortino-ratio/\n",
    "    # 15.1 Sharpe Ratio\n",
    "    # denominator - month(12), day(252)\n",
    "    denominator = NUM_OF_DAYS\n",
    "    df['excess_rtn'] = df['rtn'] - df['riskfree']/denominator\n",
    "    sharpe_rto = df['excess_rtn'].mean() /  df['excess_rtn'].std() * np.sqrt(denominator)\n",
    "    result['sharpe_rto'] = sharpe_rto\n",
    "\n",
    "    # 15.2 Sortino Ratio\n",
    "    target = 0\n",
    "    df['downside_rtn'] = 0\n",
    "    df.loc[df['rtn'] < target, 'downside_rtn'] = df['rtn']**2\n",
    "    down_stdev = np.sqrt(df['downside_rtn'].mean())\n",
    "    sortino_ratio = df['excess_rtn'].mean()/down_stdev * np.sqrt(denominator)\n",
    "    result['sortino_rto'] = sortino_ratio\n",
    "    result['down_dev'] = down_stdev\n",
    "\n",
    "    # downside_stdev 를 excess_rtn으로 계산\n",
    "    #m_idx['downside_rtn2'] = 0\n",
    "    #m_idx.loc[m_idx['excess_rtn'] < target, 'downside_rtn2'] = m_idx['excess_rtn']**2\n",
    "    #down_stdev2 = np.sqrt(m_idx['downside_rtn2'].mean())\n",
    "    #sortino_ratio = m_idx['excess_rtn'].mean()/down_stdev2 * np.sqrt(denominator)\n",
    "\n",
    "    # 16. [vsMarket] Beta, Alpha, R-squared, correlation\n",
    "    # Beta, Alpha, R squared 참고사이트\n",
    "    # http://gouthamanbalaraman.com/blog/calculating-stock-beta.html\n",
    "    # https://stackoverflow.com/questions/893657/how-do-i-calculate-r-squared-using-python-and-numpy\n",
    "\n",
    "    # 16.1 Beta\n",
    "    covariance = np.cov(df['rtn'], df['kospi_rtn'])\n",
    "    # variance는 np.var로 구할수도 있으나, covariance[1,1] 과 같다\n",
    "    #variance = np.var(m_idx['mkt_rtn'],ddof=1)\n",
    "    beta = covariance[0,1] / covariance[1,1]\n",
    "    result['vs_market']['beta'] = beta\n",
    "\n",
    "    # 16.2 Alpha\n",
    "    alpha = df['rtn'].mean() - beta*(df['kospi_rtn'].mean())\n",
    "    #연환산\n",
    "    y_alpha = (1 + alpha) ** NUM_OF_DAYS - 1\n",
    "    result['vs_market']['alpha'] = y_alpha\n",
    "\n",
    "    # 16.3 R squared \n",
    "    # R2 - numpy_manual\n",
    "\n",
    "    ypred = alpha + beta * df['kospi_rtn']\n",
    "    SS_res = np.sum(np.power(ypred - df['rtn'],2))\n",
    "    SS_tot = covariance[0,0] * (len(df) - 1) # SS_TOT is sample_variance*(n-1)\n",
    "    r_squared = 1. - SS_res/SS_tot\n",
    "    result['vs_market']['r2'] = r_squared\n",
    "\n",
    "    # 1year momentum (bonus) \n",
    "    momentum = np.prod(1+df['rtn'].tail(NUM_OF_DAYS).values) - 1\n",
    "\n",
    "    # 16.4 correlation\n",
    "    # 비교를 위해 'rtn', 'mkt_rtn'만 새로운 dataframe 으로 copy\n",
    "    #new_df = m_idx[['rtn','mkt_rtn']].copy()\n",
    "    #corr = new_df.corr()\n",
    "    corr = df['rtn'].corr(df['kospi_rtn'])\n",
    "    result['vs_market']['corr'] = corr\n",
    "    \n",
    "    if 'benchmark' in df.columns:\n",
    "        \n",
    "        # 17. [vsBenchmark] Beta, Alpha, R-squared, correlation\n",
    "        # Beta, Alpha, R squared 참고사이트\n",
    "        # http://gouthamanbalaraman.com/blog/calculating-stock-beta.html\n",
    "        # https://stackoverflow.com/questions/893657/how-do-i-calculate-r-squared-using-python-and-numpy\n",
    "\n",
    "        # 17.1 Beta\n",
    "        covariance = np.cov(df['rtn'], df['bm_rtn'])\n",
    "        # variance는 np.var로 구할수도 있으나, covariance[1,1] 과 같다\n",
    "        #variance = np.var(m_idx['mkt_rtn'],ddof=1)\n",
    "        beta = covariance[0,1] / covariance[1,1]\n",
    "        result['vs_benchmark']['beta'] = beta\n",
    "\n",
    "        # 17.2 Alpha\n",
    "        alpha = df['rtn'].mean() - beta*(df['bm_rtn'].mean())\n",
    "        #연환산\n",
    "        y_alpha = (1 + alpha) ** NUM_OF_DAYS - 1\n",
    "        result['vs_benchmark']['alpha'] = y_alpha\n",
    "\n",
    "        # 17.3 R squared \n",
    "        # R2 - numpy_manual\n",
    "\n",
    "        ypred = alpha + beta * df['bm_rtn']\n",
    "        SS_res = np.sum(np.power(ypred - df['rtn'],2))\n",
    "        SS_tot = covariance[0,0] * (len(df) - 1) # SS_TOT is sample_variance*(n-1)\n",
    "        r_squared = 1. - SS_res/SS_tot\n",
    "        result['vs_benchmark']['r2'] = r_squared\n",
    "\n",
    "        # 17.4 correlation\n",
    "        # 비교를 위해 'rtn', 'mkt_rtn'만 새로운 dataframe 으로 copy\n",
    "        #new_df = m_idx[['rtn','mkt_rtn']].copy()\n",
    "        #corr = new_df.corr()\n",
    "        corr = df['rtn'].corr(df['bm_rtn'])\n",
    "        result['vs_benchmark']['corr'] = corr\n",
    "    \n",
    "    return result\n",
    "\n",
    "def show_result(rslt) :\n",
    "    for key in rslt.keys() :\n",
    "        print(\"Final Balance : \" , int(rslt[key]['final_balance']))\n",
    "        print(\"CAGR : \", round(rslt[key]['cagr'] * 100, 5), \"%\" )\n",
    "        print(\"Stdev : \", round(rslt[key]['annlzd_stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Best Year (\",rslt[key]['best_y']['year'],\") : \", round(rslt[key]['best_y']['rtn'] * 100, 5), \"%\" )\n",
    "        print(\"Worst Year (\",rslt[key]['worst_y']['year'],\") : \", round(rslt[key]['worst_y']['rtn'] * 100, 5), \"%\" )\n",
    "        print(\"MDD : \", round(rslt[key]['mdd'] * 100, 5), \"%\" )\n",
    "        print(\"Sharpe Ratio : \", round(rslt[key]['sharpe_rto'], 5))\n",
    "        print(\"Sortino Ratio : \", round(rslt[key]['sortino_rto'], 5))\n",
    "        print(\"Korean MKT Correlation : \", round(rslt[key]['vs_market']['corr'], 5))\n",
    "        print(\"Arithmetic Mean (daily) : \", round(rslt[key]['arith_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Arithmetic Mean (annualized) : \", round(rslt[key]['annlzd_arith_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Geometric Mean (daily) : \", round(rslt[key]['geo_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Geometric Mean (annualized) : \", round(rslt[key]['annlzd_geo_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Volatility (daily) : \", round(rslt[key]['stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Volatility (annualized) : \", round(rslt[key]['annlzd_stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Downside Deviation (daily) : \", round(rslt[key]['down_dev'] * 100, 5), \"%\" )\n",
    "        print(\"MDD : \", round(rslt[key]['mdd'] * 100, 5), \"%\" )\n",
    "        print(\"Korean MKT Correlation : \", round(rslt[key]['vs_market']['corr'], 5))\n",
    "        print(\"Beta(vs market) : \", round(rslt[key]['vs_market']['beta'], 5))\n",
    "        print(\"Alpha(vs market, annualized) : \", round(rslt[key]['vs_market']['alpha']*100, 5),\"%\")\n",
    "        print(\"R2(vs market) : \", round(rslt[key]['vs_market']['r2']*100, 5),\"%\")\n",
    "        print(\"Beta(vs benchmark) : \", round(rslt[key]['vs_benchmark']['beta'], 5))\n",
    "        print(\"Alpha(vs benchmark, annualized) : \", round(rslt[key]['vs_benchmark']['alpha']*100, 5),\"%\")\n",
    "        print(\"R2(vs benchmark) : \", round(rslt[key]['vs_benchmark']['r2']*100, 5),\"%\")\n",
    "        print(\"Sharpe Ratio : \", round(rslt[key]['sharpe_rto'], 5))\n",
    "        print(\"Sortino Ratio : \", round(rslt[key]['sortino_rto'], 5))\n",
    "        print(\"Skewness : \", round(rslt[key]['skewness'], 5))\n",
    "        print(\"Excess Kurtosis : \", round(rslt[key]['kurtosis'], 5))\n",
    "        print(\"Historical VaR(5%) : \", round(rslt[key]['hist_var']*100, 5),\"%\")\n",
    "        print(\"Analytical VaR(5%) : \", round(rslt[key]['anal_var']*100, 5),\"%\")\n",
    "        print(\"Conditional VaR(5%) : \", round(rslt[key]['c_var']*100, 5),\"%\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tm_data = init_analyze(result_df)\n",
    "    rslt = dict.fromkeys(['backtest','benchmark'])\n",
    "    rslt['backtest'] = analyze_data(tm_data)\n",
    "\n",
    "    if 'benchmark' in tm_data.columns:\n",
    "        tm_data['backtest'] = tm_data['benchmark']\n",
    "        tm_data['rtn'] = tm_data['bm_rtn']\n",
    "        tm_data['prev'] = tm_data['bm_prev']\n",
    "        rslt['benchmark'] = analyze_data(tm_data)\n",
    "    show_result(rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 가까운 다음 날짜(index) 찾기 예제\n",
    "\n",
    "dt = '2018-01-06'\n",
    "\n",
    "# method 옵션 - nearest :가장가까운놈, backfill/bfill: Next, pad/ffill : Previous\n",
    "mm = wght_t.index.get_loc(dt,method='bfill')\n",
    "find_index = wght_t.index[wght_t.index.get_loc(dt,method='bfill')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-08 00:00:00')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "wght_t.to_excel(\"tttt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표!! 포트폴리오 구성종목, 벤치마크, kospi, riskfree의 일별 가격을 excel로 읽어 json으로 넘기자.\n",
    "# 각 종목별 엑셀파일을 읽어서 datafram -> json !!\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import json\n",
    "\n",
    "def make_input ():\n",
    "\n",
    "    #입력포맷\n",
    "    my_input = {'start_date' : '2018-01-01',\n",
    "                'init_index' : 1000,\n",
    "                'init_amt' : 1000000,\n",
    "                'portfolio' : ['069500','261220','332940','371450','HERO','SPY'],\n",
    "                'rebalancing' : {\n",
    "                    '2018-01-01' : [15,15,20,25,15,10],\n",
    "                    '2019-01-01' : [15,15,20,25,15,10],\n",
    "                    '2020-01-01' : [15,15,20,25,15,10],\n",
    "                    '2021-01-01' : [15,15,20,25,15,10]},\n",
    "                'history' : {}               \n",
    "                }\n",
    "\n",
    "    # 포트폴리오가격 엑셀에서 가져오기\n",
    "    for item in my_input['portfolio'] :\n",
    "        # excel 파일 읽기\n",
    "        infile = 'price_' + item + '.xlsx'\n",
    "        df = pd.read_excel(infile,dtype='unicode')\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "        df['DATE'] = df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "        #my_input[item] = df.to_dict('records')\n",
    "        my_input['history'][item] = df.values.tolist()  # 리스트가 가벼워보여...\n",
    "\n",
    "    # benchmark 엘셀에서 가져오기\n",
    "    infile = \"benchmark.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['benchmark'] = tmp_df.values.tolist()\n",
    "\n",
    "    # riskfree 엘셀에서 가져오기\n",
    "    infile = \"riskfree.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['riskfree'] = tmp_df.values.tolist()\n",
    "\n",
    "    # 마켓지표(KOSPI) 엘셀에서 가져오기\n",
    "    infile = \"kospi.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['kospi'] = tmp_df.values.tolist()\n",
    "\n",
    "    my_json = json.dumps(my_input)  \n",
    "    #f = open(\"input.json\",'w')\n",
    "    #f.write(my_json)\n",
    "    #f.close()\n",
    "    return my_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa = generate_input()\n",
    "def data_preprocess(my_config) :\n",
    "\n",
    "    hist_list = []\n",
    "    # dictionary -> dataframe\n",
    "    # 시계열데이터 다루는 작업은 dataframe이 좋다\n",
    "    for key, value in my_config['history'].items():\n",
    "        tmp_df = pd.DataFrame(value, columns=['DATE',key])\n",
    "        tmp_df.set_index('DATE',inplace=True)\n",
    "        tmp_df.index = pd.to_datetime(tmp_df.index) \n",
    "        tmp_df[key] = tmp_df[key].astype(float)\n",
    "        hist_list.append(tmp_df)\n",
    "\n",
    "    # 자산이 소속된 국가/거래소별로 시계열이 다를 수 있다. 그래서...\n",
    "    # 1. 하나의 DATAFRAME으로 합친다. \n",
    "    prc_df = pd.concat(hist_list,join='outer',axis=1)\n",
    "    # 2. 결측갑(N/A)를 처리한다.  method='pad'를 넣으면 N/A부분을 직전값으로 대체한다. \n",
    "    # 이때 상장이 늦게된종목의 경우 앞에서 부터 계속 N/A이므로 결측값의 대체가 어렵다 (나중에 0으로 바꿀지 고민해보자)\n",
    "    prc_df.fillna(method='pad',inplace=True)\n",
    "\n",
    "    # prc_df에서 [벤치마크/무위험이자율/KOSPI]와 포트폴리오 시계열을 분리한다.\n",
    "    etc_df = prc_df[['benchmark','riskfree','kospi']].copy()\n",
    "\n",
    "    #만약 벤치마크 앞쪽데이터가 없을 경우엔 데이터가 있는 날짜의 데이터로 채운다.\n",
    "    #시계열 분석시 직전 데이터로 채워야하나(method='pad'), 힘빼지말자...\n",
    "    etc_df.fillna(method='bfill',inplace=True)\n",
    "\n",
    "    #벤치마크를 지수와 같은 스케일(첫시작을 1000)로 변환한다.\n",
    "    #ratio = config['init_index'] / etc_df.iloc[0].loc['benchmark']\n",
    "    #etc_df['BM1000'] = etc_df['benchmark'] * ratio\n",
    "\n",
    "    # 포트폴리오 시계열에서 BM 삭제\n",
    "    prc_df.drop(['benchmark','riskfree','kospi'],axis=1,inplace=True)\n",
    "\n",
    "    # 포트폴리오 일별 수익률 df 생성\n",
    "    rtn_df = prc_df.pct_change()\n",
    "    rtn_df.fillna(0,inplace=True) # 첫날의 수익률은 0으로 SET\n",
    "\n",
    "    # 타켓비중설정 (리벨런싱 반영) 후 df 생성\n",
    "    target_wght_df = pd.DataFrame(data=None, columns=rtn_df.columns, index=rtn_df.index)\n",
    "    for key, value in my_config['rebalancing'].items() :\n",
    "        myindex = target_wght_df.index[target_wght_df.index.get_loc(key,method='bfill')]\n",
    "        target_wght_df.loc[myindex] = [ x / 100 for x in value ]\n",
    "    \n",
    "    return { 'prc' : prc_df,\n",
    "            'rtn' : rtn_df,\n",
    "            'target_wght' : target_wght_df,\n",
    "            'etc' : etc_df }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(init_index, init_amt, rtn_df, target_wght_df) :\n",
    "    ## 초기값 세팅\n",
    "    my_index = init_index\n",
    "    my_deposit = init_amt\n",
    "\n",
    "    tot_rtn_list = []\n",
    "    my_index_list = []\n",
    "    my_deposit_list = []\n",
    "\n",
    "    ##빠른 loop처리를 위해 dict로 변환 후 iteration 작업 (df -> dict -> list)\n",
    "    rtn_dict = rtn_df.to_dict('split')\n",
    "    rtns = rtn_dict['data']\n",
    "\n",
    "    wght_dict = target_wght_df.to_dict('split')\n",
    "    wghts = wght_dict['data']\n",
    "\n",
    "    ## 지수 계산 시작\n",
    "    for i in range(0,len(rtns)) :\n",
    "        tot_rtn = sum([ x*y for (x,y) in zip(rtns[i], wghts[i]) ]) / sum(wghts[i])\n",
    "        my_index = my_index * (1+tot_rtn)\n",
    "        my_deposit = my_deposit * (1+tot_rtn)\n",
    "    \n",
    "        tot_rtn_list.append(tot_rtn)\n",
    "        my_index_list.append(my_index)\n",
    "        my_deposit_list.append(my_deposit)\n",
    "    \n",
    "        # 다음 wghts 값이 미리설정되지 않았다면, 수익률을 반영한 비중을 계산한다. 즉, 리벨런싱은 skip\n",
    "        if i < ( len(rtns) -1 ) :\n",
    "            if  np.isnan(wghts[i+1]).any() :\n",
    "                wghts[i+1] = [ (1+x)*y for (x,y) in zip(rtns[i],wghts[i])]\n",
    "    \n",
    "    index_df = pd.DataFrame({'backtest':my_index_list, 'rtn':tot_rtn_list, 'deposit':my_deposit_list},index=rtn_df.index)\n",
    "    weight_df =  pd.DataFrame(data=wghts, columns=target_wght_df.columns, index=target_wght_df.index)\n",
    "\n",
    "    return {'index': index_df, 'weight': weight_df}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트용 인풋을 자체생성함\n",
    "test_json = make_input()\n",
    "\n",
    "my_config = json.loads(test_json)\n",
    "\n",
    "# 시계열 데이터를 전처리한다.\n",
    "my_timeseries = data_preprocess(my_config)\n",
    "\n",
    "# 일별 지수 및 종목비중 생성(backtest)\n",
    "backtest_result = generate_index(my_config['init_index'],my_config['init_amt'],result['rtn'],result['target_wght'] )\n",
    "\n",
    "# 시계열 분석 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['index', 'weight'])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "backtest_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerere = generate_index(my_config['init_index'],my_config['init_amt'],result['rtn'],result['target_wght'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              069500    261220    332940    371450      HERO       SPY\n",
       "DATE                                                                  \n",
       "2018-01-02  0.150000  0.150000  0.200000  0.250000  0.150000  0.100000\n",
       "2018-01-03  0.150000  0.150000  0.200000  0.250000  0.150000  0.100000\n",
       "2018-01-04  0.150636  0.149103  0.200000  0.250000  0.150000  0.100633\n",
       "2018-01-05  0.149456  0.153482  0.200000  0.250000  0.150000  0.101057\n",
       "2018-01-08  0.151481  0.153051  0.200000  0.250000  0.150000  0.101730\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2021-04-05  0.163657  0.187397  0.214534  0.243925  0.155169  0.107149\n",
       "2021-04-06  0.163980  0.187913  0.216025  0.243008  0.156957  0.108687\n",
       "2021-04-07  0.164208  0.184814  0.216522  0.241862  0.157391  0.108623\n",
       "2021-04-08  0.164607  0.184401  0.216832  0.242779  0.156570  0.108749\n",
       "2021-04-09  0.164455  0.183678  0.215839  0.242435  0.158792  0.109265\n",
       "\n",
       "[848 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>069500</th>\n      <th>261220</th>\n      <th>332940</th>\n      <th>371450</th>\n      <th>HERO</th>\n      <th>SPY</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-02</th>\n      <td>0.150000</td>\n      <td>0.150000</td>\n      <td>0.200000</td>\n      <td>0.250000</td>\n      <td>0.150000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>2018-01-03</th>\n      <td>0.150000</td>\n      <td>0.150000</td>\n      <td>0.200000</td>\n      <td>0.250000</td>\n      <td>0.150000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>2018-01-04</th>\n      <td>0.150636</td>\n      <td>0.149103</td>\n      <td>0.200000</td>\n      <td>0.250000</td>\n      <td>0.150000</td>\n      <td>0.100633</td>\n    </tr>\n    <tr>\n      <th>2018-01-05</th>\n      <td>0.149456</td>\n      <td>0.153482</td>\n      <td>0.200000</td>\n      <td>0.250000</td>\n      <td>0.150000</td>\n      <td>0.101057</td>\n    </tr>\n    <tr>\n      <th>2018-01-08</th>\n      <td>0.151481</td>\n      <td>0.153051</td>\n      <td>0.200000</td>\n      <td>0.250000</td>\n      <td>0.150000</td>\n      <td>0.101730</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-04-05</th>\n      <td>0.163657</td>\n      <td>0.187397</td>\n      <td>0.214534</td>\n      <td>0.243925</td>\n      <td>0.155169</td>\n      <td>0.107149</td>\n    </tr>\n    <tr>\n      <th>2021-04-06</th>\n      <td>0.163980</td>\n      <td>0.187913</td>\n      <td>0.216025</td>\n      <td>0.243008</td>\n      <td>0.156957</td>\n      <td>0.108687</td>\n    </tr>\n    <tr>\n      <th>2021-04-07</th>\n      <td>0.164208</td>\n      <td>0.184814</td>\n      <td>0.216522</td>\n      <td>0.241862</td>\n      <td>0.157391</td>\n      <td>0.108623</td>\n    </tr>\n    <tr>\n      <th>2021-04-08</th>\n      <td>0.164607</td>\n      <td>0.184401</td>\n      <td>0.216832</td>\n      <td>0.242779</td>\n      <td>0.156570</td>\n      <td>0.108749</td>\n    </tr>\n    <tr>\n      <th>2021-04-09</th>\n      <td>0.164455</td>\n      <td>0.183678</td>\n      <td>0.215839</td>\n      <td>0.242435</td>\n      <td>0.158792</td>\n      <td>0.109265</td>\n    </tr>\n  </tbody>\n</table>\n<p>848 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "  rerere['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0e8940225f2a43e2c38c1d3a557ff271b18f55a3e3b6fcd3d3f07aa560eb6a05c",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}