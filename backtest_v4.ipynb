{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "시작 : 0.0 sec\n테스트데이터 로드 : 0.4518284797668457 sec\n시계열 데이터 전처리 : 0.05580902099609375 sec\n지수산출 : 0.03291201591491699 sec\n시계열분석 : 0.09474682807922363 sec\n총 소요시간 : 0.6352963447570801 sec\n"
     ]
    }
   ],
   "source": [
    "# 목표!! 포트폴리오 구성종목, 벤치마크, kospi, riskfree의 일별 가격을 excel로 읽어 json으로 넘기자.\n",
    "# 각 종목별 엑셀파일을 읽어서 datafram -> json !!\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "import simplejson\n",
    "\n",
    "def make_input ():\n",
    "\n",
    "    #입력포맷\n",
    "    my_input = {'start_date' : '2018-01-01',\n",
    "                'init_index' : 1000,\n",
    "                'init_amt' : 1000000,\n",
    "                'portfolio' : ['069500','261220','332940','371450','HERO','SPY'],\n",
    "                'rebalancing' : {\n",
    "                    '2018-01-01' : [15,15,20,25,15,10],\n",
    "                    '2019-01-01' : [15,15,20,25,15,10],\n",
    "                    '2020-01-01' : [15,15,20,25,15,10],\n",
    "                    '2021-01-01' : [15,15,20,25,15,10]},\n",
    "                'history' : {}               \n",
    "                }\n",
    "\n",
    "    # 포트폴리오가격 엑셀에서 가져오기\n",
    "    for item in my_input['portfolio'] :\n",
    "        # excel 파일 읽기\n",
    "        infile = 'price_' + item + '.xlsx'\n",
    "        df = pd.read_excel(infile,dtype='unicode')\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "        df['DATE'] = df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "        #my_input[item] = df.to_dict('records')\n",
    "        my_input['history'][item] = df.values.tolist()  # 리스트가 가벼워보여...\n",
    "\n",
    "    # benchmark 엘셀에서 가져오기\n",
    "    infile = \"benchmark.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['benchmark'] = tmp_df.values.tolist()\n",
    "\n",
    "    # riskfree 엘셀에서 가져오기\n",
    "    infile = \"riskfree.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['riskfree'] = tmp_df.values.tolist()\n",
    "\n",
    "    # 마켓지표(KOSPI) 엘셀에서 가져오기\n",
    "    infile = \"kospi.xlsx\"\n",
    "    tmp_df = pd.read_excel(infile,dtype='unicode')\n",
    "    tmp_df['DATE'] = pd.to_datetime(tmp_df['DATE'])\n",
    "    tmp_df['DATE'] = tmp_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    my_input['history']['kospi'] = tmp_df.values.tolist()\n",
    "\n",
    "    my_json = json.dumps(my_input)  \n",
    "    #f = open(\"input.json\",'w')\n",
    "    #f.write(my_json)\n",
    "    #f.close()\n",
    "    return my_json\n",
    "\n",
    "# 시계열 데이터 전처리 (서로다른 시계열을 하나로 합치고 결측치를 보정한다)\n",
    "def data_preprocess(my_config) :\n",
    "\n",
    "    hist_list = []\n",
    "    # dictionary -> dataframe\n",
    "    # 시계열데이터 다루는 작업은 dataframe이 좋다\n",
    "    for key, value in my_config['history'].items():\n",
    "        tmp_df = pd.DataFrame(value, columns=['DATE',key])\n",
    "        tmp_df.set_index('DATE',inplace=True)\n",
    "        tmp_df.index = pd.to_datetime(tmp_df.index) \n",
    "        tmp_df[key] = tmp_df[key].astype(float)\n",
    "        hist_list.append(tmp_df)\n",
    "\n",
    "    # 자산이 소속된 국가/거래소별로 시계열이 다를 수 있다. 그래서...\n",
    "    # 1. 하나의 DATAFRAME으로 합친다. \n",
    "    prc_df = pd.concat(hist_list,join='outer',axis=1)\n",
    "    # 2. 결측갑(N/A)를 처리한다.  method='pad'를 넣으면 N/A부분을 직전값으로 대체한다. \n",
    "    # 이때 상장이 늦게된종목의 경우 앞에서 부터 계속 N/A이므로 결측값의 대체가 어렵다 (나중에 0으로 바꿀지 고민해보자)\n",
    "    prc_df.fillna(method='pad',inplace=True)\n",
    "\n",
    "    # prc_df에서 [벤치마크/무위험이자율/KOSPI]와 포트폴리오 시계열을 분리한다.\n",
    "    etc_df = prc_df[['benchmark','riskfree','kospi']].copy()\n",
    "\n",
    "    #만약 벤치마크 앞쪽데이터가 없을 경우엔 데이터가 있는 날짜의 데이터로 채운다.\n",
    "    #시계열 분석시 직전 데이터로 채워야하나(method='pad'), 힘빼지말자...\n",
    "    etc_df.fillna(method='bfill',inplace=True)\n",
    "\n",
    "    #벤치마크를 지수와 같은 스케일(첫시작을 1000)로 변환한다.\n",
    "    #ratio = config['init_index'] / etc_df.iloc[0].loc['benchmark']\n",
    "    #etc_df['BM1000'] = etc_df['benchmark'] * ratio\n",
    "\n",
    "    # 포트폴리오 시계열에서 BM 삭제\n",
    "    prc_df.drop(['benchmark','riskfree','kospi'],axis=1,inplace=True)\n",
    "\n",
    "    # 포트폴리오 일별 수익률 df 생성\n",
    "    rtn_df = prc_df.pct_change()\n",
    "    rtn_df.fillna(0,inplace=True) # 첫날의 수익률은 0으로 SET\n",
    "\n",
    "    # 타켓비중설정 (리벨런싱 반영) 후 df 생성\n",
    "    target_wght_df = pd.DataFrame(data=None, columns=rtn_df.columns, index=rtn_df.index)\n",
    "    for key, value in my_config['rebalancing'].items() :\n",
    "        myindex = target_wght_df.index[target_wght_df.index.get_loc(key,method='bfill')]\n",
    "        target_wght_df.loc[myindex] = [ x / 100 for x in value ]\n",
    "    \n",
    "    return { 'prc' : prc_df,\n",
    "            'rtn' : rtn_df,\n",
    "            'target_wght' : target_wght_df,\n",
    "            'etc' : etc_df }\n",
    "\n",
    "# 지수산출\n",
    "def generate_index(init_index, init_amt, rtn_df, target_wght_df) :\n",
    "    ## 초기값 세팅\n",
    "    my_index = init_index\n",
    "    my_deposit = init_amt\n",
    "\n",
    "    tot_rtn_list = []\n",
    "    my_index_list = []\n",
    "    my_deposit_list = []\n",
    "\n",
    "    ##빠른 loop처리를 위해 dict로 변환 후 iteration 작업 (df -> dict -> list)\n",
    "    rtn_dict = rtn_df.to_dict('split')\n",
    "    rtns = rtn_dict['data']\n",
    "\n",
    "    wght_dict = target_wght_df.to_dict('split')\n",
    "    wghts = wght_dict['data']\n",
    "\n",
    "    ## 지수 계산 시작\n",
    "    for i in range(0,len(rtns)) :\n",
    "        tot_rtn = sum([ x*y for (x,y) in zip(rtns[i], wghts[i]) ]) / sum(wghts[i])\n",
    "        my_index = my_index * (1+tot_rtn)\n",
    "        my_deposit = my_deposit * (1+tot_rtn)\n",
    "    \n",
    "        tot_rtn_list.append(tot_rtn)\n",
    "        my_index_list.append(my_index)\n",
    "        my_deposit_list.append(my_deposit)\n",
    "    \n",
    "        # 다음 wghts 값이 미리설정되지 않았다면, 수익률을 반영한 비중을 계산한다. 즉, 리벨런싱은 skip\n",
    "        if i < ( len(rtns) -1 ) :\n",
    "            if  np.isnan(wghts[i+1]).any() :\n",
    "                wghts[i+1] = [ (1+x)*y for (x,y) in zip(rtns[i],wghts[i])]\n",
    "    \n",
    "    index_df = pd.DataFrame({'backtest':my_index_list, 'rtn':tot_rtn_list, 'deposit':my_deposit_list},index=rtn_df.index)\n",
    "    weight_df =  pd.DataFrame(data=wghts, columns=target_wght_df.columns, index=target_wght_df.index)\n",
    "\n",
    "    return {'index': index_df, 'weight': weight_df}\n",
    "\n",
    "\n",
    "# 시계열 분석을 위한 초기화\n",
    "def init_analyze(input_df) :\n",
    "    df = input_df.copy()\n",
    "    df.rename(columns={'DATE':'date'},inplace=True)\n",
    "    df.set_index(['date'],inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['prev'] = df['backtest'].shift(1)\n",
    "    df['kospi_rtn'] = df['kospi'].pct_change()\n",
    "    df['bm_prev'] = df['benchmark'].shift(1)\n",
    "    df['bm_rtn'] = df['benchmark'].pct_change()\n",
    "    df['riskfree'] = df['riskfree'] / 100\n",
    "\n",
    "    # 시계열 분석 편의를 위해 첫데이터를 날린다.\n",
    "    df = df.iloc[1:]\n",
    "    return df\n",
    "\n",
    "# 분석결과 자료 초기화\n",
    "def init_result():\n",
    "    return {\n",
    "    'final_balance' : 0,\n",
    "    'cagr' : 0,\n",
    "    'stdev' : 0,\n",
    "    'annlzd_stdev' : 0,\n",
    "    'arith_mean' : 0,\n",
    "    'annlzd_arith_mean' : 0,\n",
    "    'geo_mean' : 0,\n",
    "    'annlzd_geo_mean' : 0,\n",
    "    'vol' : 0,\n",
    "    'annlzd_vol' : 0,\n",
    "    'hist_var' : 0,\n",
    "    'anal_var' : 0,\n",
    "    'c_var' : 0,\n",
    "    'best_y' : {'year' : 0, 'rtn' : 0},\n",
    "    'worst_y' : {'year' : 0, 'rtn' : 0},\n",
    "    'mdd' : 0,\n",
    "    'skewness' : 0,\n",
    "    'kurtosis' : 0,\n",
    "    'sharpe_rto' : 0,\n",
    "    'sortino_rto' : 0,\n",
    "    'down_dev' : 0,\n",
    "    'vs_market' : {'beta' : 0, 'alpha' : 0, 'r2' : 0, 'corr' : 0},\n",
    "    'vs_benchmark' : {'beta' : 0, 'alpha' : 0, 'r2' : 0, 'corr' : 0}\n",
    "    }\n",
    "\n",
    "# 시계열 데이터 분석\n",
    "def analyze_data(initial_balance, df):\n",
    "    \n",
    "    result = init_result()\n",
    "    \n",
    "    NUM_OF_DAYS = 252\n",
    "    \n",
    "    # 1. Final Balance\n",
    "    #initial_balance = 1000000\n",
    "    final_balance = initial_balance * df['backtest'].iloc[-1] / df['prev'].iloc[0]\n",
    "    result['final_balance'] = final_balance\n",
    "\n",
    "    # 2. CAGR \n",
    "    year = df['backtest'].count() / NUM_OF_DAYS\n",
    "    # 2000-12월 종가는 2001-1월의 전일가격을 사용\n",
    "    CAGR = ( df.iloc[-1]['backtest'] / df.iloc[0]['prev'] )**(1/year) - 1\n",
    "    result['cagr'] = CAGR\n",
    "\n",
    "    # 3. Stdev (Annualized standard deviation of monthly returns)\n",
    "    stdev = df['rtn'].std()\n",
    "    result['stdev'] = stdev\n",
    "    # 연간화를 위해 루트 NUM_OF_DAYS 를 곱한다.\n",
    "    annlzd_stdev = stdev*(NUM_OF_DAYS**0.5)\n",
    "    result['annlzd_stdev'] = annlzd_stdev\n",
    "    result['vol'] = stdev\n",
    "    result['annlzd_vol'] = annlzd_stdev\n",
    "\n",
    "    # 4. Arithmetic Mean (monthly). \n",
    "    arith_mean = df['rtn'].mean()\n",
    "    result['arith_mean'] = arith_mean\n",
    "\n",
    "    # 5. Arithmetic Mean (annualized).\n",
    "    annualized_arith_mean = (1 + arith_mean) ** NUM_OF_DAYS - 1\n",
    "    result['annlzd_arith_mean'] = annualized_arith_mean\n",
    "\n",
    "    # 6. Geometric Mean, scipy 의 gmean사용\n",
    "    # 수익률의 기하평균은 각 수익률에 1을 더한후 루트를 적용, 이후에 1을 뺀다\n",
    "    # monthly_rtn의 모든 컬럼값에 1을 더한다\n",
    "    df['rtn_1'] = df['rtn'] + 1\n",
    "    # gmean은 list형의 인자를 받는다\n",
    "    geo_mean = gmean(df['rtn_1'].tolist()) - 1\n",
    "    result['geo_mean'] = geo_mean\n",
    "\n",
    "    # 7. Geometric Mean(annualized)\n",
    "    annualized_geo_mean = ( 1 + geo_mean) ** NUM_OF_DAYS - 1\n",
    "    result['annlzd_geo_mean'] = annualized_geo_mean\n",
    "\n",
    "    # 8. Volatility (monthly) . 변동성은 표준편차를 의미\n",
    "    #stdev = m_idx['rtn'].std() \n",
    "    #result['stdev'] = stdev\n",
    "\n",
    "    # 9. Volatility (annualized). 3에서 구한 Stdev와 같은 값이다\n",
    "    # 연간화를 위해 루트12 를 곱한다.\n",
    "    #stdev = stdev*(12**0.5)\n",
    "\n",
    "    # 10. VaR\n",
    "    # 10.1 Historical VaR \n",
    "    # exclusive quantile을 자체 구현\n",
    "    def quantile_exc(df2, q):\n",
    "        list_sorted = sorted(df2) # sorted()는 list형의 결과를 리턴한다\n",
    "        rank = q * (len(list_sorted) + 1) - 1\n",
    "        #print (\"q_exc : \", rank)\n",
    "        #assert rank > 0, 'quantile is too small'\n",
    "        if rank < 0 :\n",
    "            print ('quantile is too small')\n",
    "            return 0\n",
    "        rank_l = int(rank)\n",
    "        return list_sorted[rank_l] + (list_sorted[rank_l + 1] - \n",
    "                                      list_sorted[rank_l]) * (rank - rank_l)\n",
    "\n",
    "    historical_var_95 = quantile_exc(df['rtn'], 0.05)\n",
    "    if (historical_var_95 == 0) :\n",
    "        historical_var_95 = df['rtn'].quantile(0.05)\n",
    "    result['hist_var'] = historical_var_95\n",
    "\n",
    "    # 10.2 Analytical VaR\n",
    "    mean = df['rtn'].mean()\n",
    "    stdev = df['rtn'].std()\n",
    "    analytical_var_95 = norm.ppf(0.05, mean, stdev)\n",
    "    result['anal_var'] = analytical_var_95\n",
    "\n",
    "    # 10.3 Conditional VaR\n",
    "    # 자체구현\n",
    "    def conditional_var(df3, q):\n",
    "        list_sorted = sorted(df3)\n",
    "        rank = q * len(list_sorted) \n",
    "        rank_l = int(rank)\n",
    "\n",
    "        sum_rtn = 0\n",
    "        sum_rtn = sum(i for i in list_sorted[0:rank_l])\n",
    "\n",
    "        return 1 / rank * sum_rtn\n",
    "\n",
    "    cvar_95 = conditional_var(df['rtn'], 0.05)\n",
    "    result['c_var'] = cvar_95\n",
    "\n",
    "    # 11. Best Year / Worst Year\n",
    "    # 년단위 데이터로 resamplingn\n",
    "    y_idx = df.resample(rule='Y').last()\n",
    "    y_idx['rtn'] = y_idx['backtest'].pct_change()\n",
    "    if len(y_idx) == 1 :\n",
    "        min_val = df['backtest'].iloc[-1] / df['prev'].iloc[0] - 1\n",
    "        min_idx = df['backtest'].idxmin()\n",
    "        max_val = df['backtest'].iloc[-1] / df['prev'].iloc[0] - 1\n",
    "        max_idx = df['backtest'].idxmax()     \n",
    "    else :\n",
    "        min_val = y_idx['rtn'].min()\n",
    "        min_idx = y_idx['rtn'].idxmin()\n",
    "        max_val = y_idx['rtn'].max()\n",
    "        max_idx = y_idx['rtn'].idxmax()\n",
    "    result['best_y']['year'] = max_idx.year\n",
    "    result['best_y']['rtn'] = max_val\n",
    "    result['worst_y']['year'] = min_idx.year\n",
    "    result['worst_y']['rtn'] = min_val\n",
    "\n",
    "    # 12. MDD, \n",
    "    # - step1.지수의 수익률을 일별 누적(1+r을 계속곱해나감). \n",
    "    # - step2. 누적수익률에 대한 MAX를 일별로 기록\n",
    "    # - step3. 일별로 누적수익률과 MAX수익률 간의 차이((CUM - MAX) / MAX) 가 가장 큰 것을 잡는다.\n",
    "\n",
    "    #  등락률에 1을 더한다\n",
    "    df['rtn_1'] = df['rtn'] + 1\n",
    "\n",
    "    # 누적수익률계산\n",
    "    df['cum'] = df['rtn_1'].cumprod()\n",
    "\n",
    "    # 누적수익률중 최고값\n",
    "    df['high'] = df['cum'].cummax()\n",
    "\n",
    "    # drawdown 계산\n",
    "    df['drawdown'] = (df['cum'] - df['high'])/df['high']\n",
    "    MDD = df['drawdown'].min()\n",
    "    result['mdd'] = MDD\n",
    "\n",
    "    # 13. Skewness\n",
    "    skewness = df['rtn'].skew()\n",
    "    result['skewness'] = skewness\n",
    "\n",
    "    # 14. Excess Kurtosis\n",
    "    ex_kurtosis = df['rtn'].kurtosis()\n",
    "    result['kurtosis'] = ex_kurtosis\n",
    "\n",
    "    # 15. Ratio\n",
    "    # https://www.quantnews.com/performance-metrics-sharpe-ratio-sortino-ratio/\n",
    "    # 15.1 Sharpe Ratio\n",
    "    # denominator - month(12), day(252)\n",
    "    denominator = NUM_OF_DAYS\n",
    "    df['excess_rtn'] = df['rtn'] - df['riskfree']/denominator\n",
    "    sharpe_rto = df['excess_rtn'].mean() /  df['excess_rtn'].std() * np.sqrt(denominator)\n",
    "    result['sharpe_rto'] = sharpe_rto\n",
    "\n",
    "    # 15.2 Sortino Ratio\n",
    "    target = 0\n",
    "    df['downside_rtn'] = 0\n",
    "    df.loc[df['rtn'] < target, 'downside_rtn'] = df['rtn']**2\n",
    "    down_stdev = np.sqrt(df['downside_rtn'].mean())\n",
    "    sortino_ratio = df['excess_rtn'].mean()/down_stdev * np.sqrt(denominator)\n",
    "    result['sortino_rto'] = sortino_ratio\n",
    "    result['down_dev'] = down_stdev\n",
    "\n",
    "    # downside_stdev 를 excess_rtn으로 계산\n",
    "    #m_idx['downside_rtn2'] = 0\n",
    "    #m_idx.loc[m_idx['excess_rtn'] < target, 'downside_rtn2'] = m_idx['excess_rtn']**2\n",
    "    #down_stdev2 = np.sqrt(m_idx['downside_rtn2'].mean())\n",
    "    #sortino_ratio = m_idx['excess_rtn'].mean()/down_stdev2 * np.sqrt(denominator)\n",
    "\n",
    "    # 16. [vsMarket] Beta, Alpha, R-squared, correlation\n",
    "    # Beta, Alpha, R squared 참고사이트\n",
    "    # http://gouthamanbalaraman.com/blog/calculating-stock-beta.html\n",
    "    # https://stackoverflow.com/questions/893657/how-do-i-calculate-r-squared-using-python-and-numpy\n",
    "\n",
    "    # 16.1 Beta\n",
    "    covariance = np.cov(df['rtn'], df['kospi_rtn'])\n",
    "    # variance는 np.var로 구할수도 있으나, covariance[1,1] 과 같다\n",
    "    #variance = np.var(m_idx['mkt_rtn'],ddof=1)\n",
    "    beta = covariance[0,1] / covariance[1,1]\n",
    "    result['vs_market']['beta'] = beta\n",
    "\n",
    "    # 16.2 Alpha\n",
    "    alpha = df['rtn'].mean() - beta*(df['kospi_rtn'].mean())\n",
    "    #연환산\n",
    "    y_alpha = (1 + alpha) ** NUM_OF_DAYS - 1\n",
    "    result['vs_market']['alpha'] = y_alpha\n",
    "\n",
    "    # 16.3 R squared \n",
    "    # R2 - numpy_manual\n",
    "\n",
    "    ypred = alpha + beta * df['kospi_rtn']\n",
    "    SS_res = np.sum(np.power(ypred - df['rtn'],2))\n",
    "    SS_tot = covariance[0,0] * (len(df) - 1) # SS_TOT is sample_variance*(n-1)\n",
    "    r_squared = 1. - SS_res/SS_tot\n",
    "    result['vs_market']['r2'] = r_squared\n",
    "\n",
    "    # 1year momentum (bonus) \n",
    "    momentum = np.prod(1+df['rtn'].tail(NUM_OF_DAYS).values) - 1\n",
    "\n",
    "    # 16.4 correlation\n",
    "    # 비교를 위해 'rtn', 'mkt_rtn'만 새로운 dataframe 으로 copy\n",
    "    #new_df = m_idx[['rtn','mkt_rtn']].copy()\n",
    "    #corr = new_df.corr()\n",
    "    corr = df['rtn'].corr(df['kospi_rtn'])\n",
    "    result['vs_market']['corr'] = corr\n",
    "    \n",
    "    if 'benchmark' in df.columns:\n",
    "        \n",
    "        # 17. [vsBenchmark] Beta, Alpha, R-squared, correlation\n",
    "        # Beta, Alpha, R squared 참고사이트\n",
    "        # http://gouthamanbalaraman.com/blog/calculating-stock-beta.html\n",
    "        # https://stackoverflow.com/questions/893657/how-do-i-calculate-r-squared-using-python-and-numpy\n",
    "\n",
    "        # 17.1 Beta\n",
    "        covariance = np.cov(df['rtn'], df['bm_rtn'])\n",
    "        # variance는 np.var로 구할수도 있으나, covariance[1,1] 과 같다\n",
    "        #variance = np.var(m_idx['mkt_rtn'],ddof=1)\n",
    "        beta = covariance[0,1] / covariance[1,1]\n",
    "        result['vs_benchmark']['beta'] = beta\n",
    "\n",
    "        # 17.2 Alpha\n",
    "        alpha = df['rtn'].mean() - beta*(df['bm_rtn'].mean())\n",
    "        #연환산\n",
    "        y_alpha = (1 + alpha) ** NUM_OF_DAYS - 1\n",
    "        result['vs_benchmark']['alpha'] = y_alpha\n",
    "\n",
    "        # 17.3 R squared \n",
    "        # R2 - numpy_manual\n",
    "\n",
    "        ypred = alpha + beta * df['bm_rtn']\n",
    "        SS_res = np.sum(np.power(ypred - df['rtn'],2))\n",
    "        SS_tot = covariance[0,0] * (len(df) - 1) # SS_TOT is sample_variance*(n-1)\n",
    "        r_squared = 1. - SS_res/SS_tot\n",
    "        result['vs_benchmark']['r2'] = r_squared\n",
    "\n",
    "        # 17.4 correlation\n",
    "        # 비교를 위해 'rtn', 'mkt_rtn'만 새로운 dataframe 으로 copy\n",
    "        #new_df = m_idx[['rtn','mkt_rtn']].copy()\n",
    "        #corr = new_df.corr()\n",
    "        corr = df['rtn'].corr(df['bm_rtn'])\n",
    "        result['vs_benchmark']['corr'] = corr\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 결과 보기\n",
    "def show_result(rslt) :\n",
    "    for key in rslt.keys() :\n",
    "        print(\"Final Balance : \" , int(rslt[key]['final_balance']))\n",
    "        print(\"CAGR : \", round(rslt[key]['cagr'] * 100, 5), \"%\" )\n",
    "        print(\"Stdev : \", round(rslt[key]['annlzd_stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Best Year (\",rslt[key]['best_y']['year'],\") : \", round(rslt[key]['best_y']['rtn'] * 100, 5), \"%\" )\n",
    "        print(\"Worst Year (\",rslt[key]['worst_y']['year'],\") : \", round(rslt[key]['worst_y']['rtn'] * 100, 5), \"%\" )\n",
    "        print(\"MDD : \", round(rslt[key]['mdd'] * 100, 5), \"%\" )\n",
    "        print(\"Sharpe Ratio : \", round(rslt[key]['sharpe_rto'], 5))\n",
    "        print(\"Sortino Ratio : \", round(rslt[key]['sortino_rto'], 5))\n",
    "        print(\"Korean MKT Correlation : \", round(rslt[key]['vs_market']['corr'], 5))\n",
    "        print(\"Arithmetic Mean (daily) : \", round(rslt[key]['arith_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Arithmetic Mean (annualized) : \", round(rslt[key]['annlzd_arith_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Geometric Mean (daily) : \", round(rslt[key]['geo_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Geometric Mean (annualized) : \", round(rslt[key]['annlzd_geo_mean'] * 100, 5), \"%\" )\n",
    "        print(\"Volatility (daily) : \", round(rslt[key]['stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Volatility (annualized) : \", round(rslt[key]['annlzd_stdev'] * 100, 5), \"%\" )\n",
    "        print(\"Downside Deviation (daily) : \", round(rslt[key]['down_dev'] * 100, 5), \"%\" )\n",
    "        print(\"MDD : \", round(rslt[key]['mdd'] * 100, 5), \"%\" )\n",
    "        print(\"Korean MKT Correlation : \", round(rslt[key]['vs_market']['corr'], 5))\n",
    "        print(\"Beta(vs market) : \", round(rslt[key]['vs_market']['beta'], 5))\n",
    "        print(\"Alpha(vs market, annualized) : \", round(rslt[key]['vs_market']['alpha']*100, 5),\"%\")\n",
    "        print(\"R2(vs market) : \", round(rslt[key]['vs_market']['r2']*100, 5),\"%\")\n",
    "        print(\"Beta(vs benchmark) : \", round(rslt[key]['vs_benchmark']['beta'], 5))\n",
    "        print(\"Alpha(vs benchmark, annualized) : \", round(rslt[key]['vs_benchmark']['alpha']*100, 5),\"%\")\n",
    "        print(\"R2(vs benchmark) : \", round(rslt[key]['vs_benchmark']['r2']*100, 5),\"%\")\n",
    "        print(\"Sharpe Ratio : \", round(rslt[key]['sharpe_rto'], 5))\n",
    "        print(\"Sortino Ratio : \", round(rslt[key]['sortino_rto'], 5))\n",
    "        print(\"Skewness : \", round(rslt[key]['skewness'], 5))\n",
    "        print(\"Excess Kurtosis : \", round(rslt[key]['kurtosis'], 5))\n",
    "        print(\"Historical VaR(5%) : \", round(rslt[key]['hist_var']*100, 5),\"%\")\n",
    "        print(\"Analytical VaR(5%) : \", round(rslt[key]['anal_var']*100, 5),\"%\")\n",
    "        print(\"Conditional VaR(5%) : \", round(rslt[key]['c_var']*100, 5),\"%\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "def print_elapsed_time(cal_tm_list):\n",
    "    # 구간별 산출소요시간 계산\n",
    "    mynp = np.array(cal_tm_list)\n",
    "    label = np.array(mynp[:,0])\n",
    "    time = np.array(mynp[:,1],dtype=float)\n",
    "    \n",
    "    tot_elapsed = time[-1] - time[0]\n",
    "\n",
    "    tm_diff = np.diff(time, axis=0)\n",
    "    tm_diff = np.insert(tm_diff,0,0,axis=0)\n",
    "\n",
    "    tm_report = np.stack((label,tm_diff))\n",
    "    for i in range(len(tm_report[0])) :\n",
    "        print (f\"{tm_report[:,i][0]} : {tm_report[:,i][1]} sec\")\n",
    "    print(f\"총 소요시간 : {tot_elapsed} sec\")\n",
    "\n",
    "def init_final_result() :\n",
    "    return {\n",
    "        'summary' : {'period' : [], 'datenum' : 0, 'deposit' : [], 'backtest' : []},\n",
    "        'timeseries' : {'label':[], 'dataset':[]},\n",
    "        'tm_anal' : { 'backtest' : {}, 'benchmark' :{} },\n",
    "        'portfolio_wght' : {'label':[], 'dataset':[]},\n",
    "        'portfolio_anal' : {'label' :[], 'dataset' : []}\n",
    "         }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #테스트용 인풋을 자체생성함\n",
    "    \n",
    "    cal_tm = []\n",
    "    cal_tm.append(['시작',time.time()])\n",
    "\n",
    "    test_json = make_input()\n",
    "\n",
    "    cal_tm.append(['테스트데이터 로드',time.time()])\n",
    "    \n",
    "    my_config = json.loads(test_json)\n",
    "\n",
    "    # 시계열 데이터를 전처리한다.\n",
    "    \n",
    "    my_timeseries = data_preprocess(my_config)\n",
    "    cal_tm.append(['시계열 데이터 전처리',time.time()])\n",
    "\n",
    "    # 일별 지수 및 종목비중 생성(backtest)\n",
    "    backtest_result = generate_index(my_config['init_index'],my_config['init_amt'],my_timeseries['rtn'],my_timeseries['target_wght'] )\n",
    "    \n",
    "    cal_tm.append(['지수산출',time.time()])\n",
    "\n",
    "    # 시계열 분석 \n",
    "    # 시계열분석을 위해, 산출된 지수값과 벤치마크, 무위험이자율, kospi지수를 합친다\n",
    "    # 지수 : backtest_result['index'] , 벤치마크,무위험,kospi : my_timeseriese['etc']\n",
    "    result_df = pd.concat([backtest_result['index'],my_timeseries['etc']],join='outer',axis=1)\n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df['DATE'] = result_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    tm_data = init_analyze(result_df)\n",
    "    tm_anal_rslt = dict.fromkeys(['backtest','benchmark'])\n",
    "    tm_anal_rslt['backtest'] = analyze_data(my_config['init_amt'], tm_data)\n",
    "\n",
    "    if 'benchmark' in tm_data.columns:\n",
    "        tm_data['backtest'] = tm_data['benchmark']\n",
    "        tm_data['rtn'] = tm_data['bm_rtn']\n",
    "        tm_data['prev'] = tm_data['bm_prev']\n",
    "        tm_anal_rslt['benchmark'] = analyze_data(my_config['init_amt'], tm_data)\n",
    "    \n",
    "    cal_tm.append(['시계열분석',time.time()])\n",
    "    \n",
    "    \n",
    "    print_elapsed_time(cal_tm)\n",
    "    \n",
    "    \n",
    "    # WAS 전송용 결과 생성\n",
    "    \n",
    "    final_result = init_final_result()\n",
    "    \n",
    "    #결과0. 요약정보 정리\n",
    "    final_result['summary']['deposit'] = [ backtest_result['index']['deposit'].iloc[0], backtest_result['index']['deposit'].iloc[-1] ]\n",
    "    final_result['summary']['backtest'] = [ backtest_result['index']['backtest'].iloc[0], backtest_result['index']['backtest'].iloc[-1] ]\n",
    "    final_result['summary']['period'] = [backtest_result['index']['deposit'].index[0].strftime('%Y-%m-%d'),  backtest_result['index']['deposit'].index[-1].strftime('%Y-%m-%d')]\n",
    "    final_result['summary']['datenum'] = len(backtest_result['index']['deposit'])\n",
    "\n",
    "\n",
    "    #결과1. 시계열 데이터 정리\n",
    "    ratio = my_config['init_index'] / result_df.iloc[0].loc['benchmark']\n",
    "    result_df['BM1000'] = result_df['benchmark'] * ratio\n",
    "    tmp_df = result_df[['DATE','backtest','benchmark','BM1000']]\n",
    "    final_result['timeseries']['labels'] = tmp_df.keys().to_list()\n",
    "    final_result['timeseries']['dataset'] = tmp_df.values.tolist()\n",
    "\n",
    "    #결과2. 시계열 분석매트릭스 정리\n",
    "    final_result['tm_anal']['backtest'] = tm_anal_rslt['backtest']\n",
    "    final_result['tm_anal']['benchmark'] = tm_anal_rslt['benchmark']\n",
    "\n",
    "    #결과3. 월별포트폴리오비중현황 정리\n",
    "    tmp_df = backtest_result['weight']\n",
    "    month_wght_df = tmp_df.resample('M').last()\n",
    "    month_wght_df.reset_index(inplace=True)\n",
    "    month_wght_df['DATE'] = month_wght_df['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    final_result['portfolio_wght']['label'] = month_wght_df.keys().to_list()\n",
    "    final_result['portfolio_wght']['dataset'] = month_wght_df.values.tolist() # np array 는 tolist()\n",
    "\n",
    "    #결과4. 포트폴리오 분석 정리\n",
    "    my_timeseries['prc'].fillna(method='bfill',inplace=True)\n",
    "    port_rtn = (my_timeseries['prc'].iloc[-1] / my_timeseries['prc'].iloc[0] - 1)\n",
    "    final_result['portfolio_anal']['label'] = port_rtn.index.tolist()\n",
    "    final_result['portfolio_anal']['dataset'] = port_rtn.values.tolist()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['summary', 'timeseries', 'tm_anal', 'portfolio_wght', 'portfolio_anal'])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "final_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'label': ['DATE', '069500', '261220', '332940', '371450', 'HERO', 'SPY'],\n",
       " 'dataset': [['2018-01-31',\n",
       "   0.15343778324485302,\n",
       "   0.16019382627422823,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.1048331286973993],\n",
       "  ['2018-02-28',\n",
       "   0.14603295351547324,\n",
       "   0.15804020100502514,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.1021058897942479],\n",
       "  ['2018-03-31',\n",
       "   0.14524634209504073,\n",
       "   0.16062455132806888,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.09790899281913903],\n",
       "  ['2018-04-30',\n",
       "   0.14832480901204184,\n",
       "   0.16916726489590814,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.0991777356103731],\n",
       "  ['2018-05-31',\n",
       "   0.14315842289265818,\n",
       "   0.1660445082555635,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10142873088514331],\n",
       "  ['2018-06-30',\n",
       "   0.13855528939531261,\n",
       "   0.1811557788944724,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10078877850950614],\n",
       "  ['2018-07-31',\n",
       "   0.13787064612197322,\n",
       "   0.17602297200287154,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10415969044164146],\n",
       "  ['2018-08-31',\n",
       "   0.13821053994561688,\n",
       "   0.1795046661880833,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10801056665550467],\n",
       "  ['2018-09-30',\n",
       "   0.14041984979930067,\n",
       "   0.18686288585786073,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10815567213602707],\n",
       "  ['2018-10-31',\n",
       "   0.12205101644438675,\n",
       "   0.17358219669777453,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.09962793466532723],\n",
       "  ['2018-11-30',\n",
       "   0.12736792697138394,\n",
       "   0.12968413496051687,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.1019384603936451],\n",
       "  ['2018-12-31',\n",
       "   0.12349799300789825,\n",
       "   0.11755204594400574,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.09217918666517842],\n",
       "  ['2019-01-31',\n",
       "   0.16397145553196513,\n",
       "   0.17340458015267185,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.10706626120358513],\n",
       "  ['2019-02-28',\n",
       "   0.16534560037744755,\n",
       "   0.18050381679389316,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11171574903969272],\n",
       "  ['2019-03-31',\n",
       "   0.15806204293465445,\n",
       "   0.18948091603053438,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11231994238156212],\n",
       "  ['2019-04-30',\n",
       "   0.16450224109459785,\n",
       "   0.20143511450381682,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11758562740076821],\n",
       "  ['2019-05-31',\n",
       "   0.15149799481009676,\n",
       "   0.18879389312977096,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.1116477272727272],\n",
       "  ['2019-06-30',\n",
       "   0.15999646142958254,\n",
       "   0.1877862595419847,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11663732394366193],\n",
       "  ['2019-07-31',\n",
       "   0.15489502241094613,\n",
       "   0.1815572519083969,\n",
       "   0.2,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.12032650448143407],\n",
       "  ['2019-08-31',\n",
       "   0.14635527246992233,\n",
       "   0.1760152671755724,\n",
       "   0.1991959798994975,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11706946222791291],\n",
       "  ['2019-09-30',\n",
       "   0.15638711960368035,\n",
       "   0.1785801526717556,\n",
       "   0.21326633165829142,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.11819782330345703],\n",
       "  ['2019-10-31',\n",
       "   0.15882283557442822,\n",
       "   0.17496183206106858,\n",
       "   0.21839195979899498,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.12169494238156203],\n",
       "  ['2019-11-30',\n",
       "   0.16245576786978091,\n",
       "   0.1833435114503815,\n",
       "   0.2223115577889447,\n",
       "   0.25,\n",
       "   0.15908183632734527,\n",
       "   0.12623239436619715],\n",
       "  ['2019-12-31',\n",
       "   0.17166194857277692,\n",
       "   0.19598473282442727,\n",
       "   0.2359798994974875,\n",
       "   0.25,\n",
       "   0.16317365269461087,\n",
       "   0.12847311139564652],\n",
       "  ['2020-01-31',\n",
       "   0.14719655065791729,\n",
       "   0.12840616966580976,\n",
       "   0.19787052810902897,\n",
       "   0.25,\n",
       "   0.15568112400733056,\n",
       "   0.10180823960728266],\n",
       "  ['2020-02-29',\n",
       "   0.14174940735905442,\n",
       "   0.1160668380462725,\n",
       "   0.1907155025553664,\n",
       "   0.25,\n",
       "   0.15210751374465498,\n",
       "   0.09243459889392901],\n",
       "  ['2020-03-31',\n",
       "   0.11938880681622965,\n",
       "   0.04907688712315963,\n",
       "   0.16047700170357762,\n",
       "   0.25,\n",
       "   0.14871716554673195,\n",
       "   0.08129310880507047],\n",
       "  ['2020-04-30',\n",
       "   0.13244236781530197,\n",
       "   0.02373218041598506,\n",
       "   0.17691652470187405,\n",
       "   0.25,\n",
       "   0.16658521686011007,\n",
       "   0.0910986143043559],\n",
       "  ['2020-05-31',\n",
       "   0.13760092074071503,\n",
       "   0.03680766534236973,\n",
       "   0.18364565587734258,\n",
       "   0.25,\n",
       "   0.18087965791081262,\n",
       "   0.09413098862859633],\n",
       "  ['2020-06-30',\n",
       "   0.14275432026660234,\n",
       "   0.042136013087169945,\n",
       "   0.1917376490630325,\n",
       "   0.25,\n",
       "   0.21047648136835695,\n",
       "   0.09459392282358793],\n",
       "  ['2020-07-31',\n",
       "   0.15504002473631745,\n",
       "   0.0455713951857911,\n",
       "   0.2069846678023851,\n",
       "   0.25,\n",
       "   0.2207391569945023,\n",
       "   0.10065245759025665],\n",
       "  ['2020-08-31',\n",
       "   0.16059538942522372,\n",
       "   0.047254031315727994,\n",
       "   0.21277683134582637,\n",
       "   0.25,\n",
       "   0.24841172877214435,\n",
       "   0.10892313428198597],\n",
       "  ['2020-09-30',\n",
       "   0.15974507850345238,\n",
       "   0.04395886889460158,\n",
       "   0.21175468483816032,\n",
       "   0.25,\n",
       "   0.24795357361026288,\n",
       "   0.10326539489218918],\n",
       "  ['2020-10-31',\n",
       "   0.15946164152952855,\n",
       "   0.04080392615096989,\n",
       "   0.21056218057921652,\n",
       "   0.25,\n",
       "   0.25061087354917555,\n",
       "   0.10252283601565898],\n",
       "  ['2020-11-30',\n",
       "   0.18128628852166098,\n",
       "   0.047955129703201725,\n",
       "   0.2413969335604772,\n",
       "   0.25,\n",
       "   0.2619731215638366,\n",
       "   0.11299011992791898],\n",
       "  ['2020-12-31',\n",
       "   0.2033170714948289,\n",
       "   0.05089974293059131,\n",
       "   0.27427597955707017,\n",
       "   0.2718095712861416,\n",
       "   0.2870800244349424,\n",
       "   0.11557509476169767],\n",
       "  ['2021-01-31',\n",
       "   0.15994981370238007,\n",
       "   0.16270661157024793,\n",
       "   0.21360248447204966,\n",
       "   0.24977074736359467,\n",
       "   0.1592753623188405,\n",
       "   0.10100299561356584],\n",
       "  ['2021-02-28',\n",
       "   0.16306744734240744,\n",
       "   0.19638429752066106,\n",
       "   0.21465838509316773,\n",
       "   0.2553874369555249,\n",
       "   0.16019323671497582,\n",
       "   0.102260083449235],\n",
       "  ['2021-03-31',\n",
       "   0.16082427191848517,\n",
       "   0.1909090909090907,\n",
       "   0.21186335403726708,\n",
       "   0.23165978908757437,\n",
       "   0.14985507246376814,\n",
       "   0.10557665561142608],\n",
       "  ['2021-04-30',\n",
       "   0.16445517451144384,\n",
       "   0.183677685950413,\n",
       "   0.21583850931677018,\n",
       "   0.24243466299862432,\n",
       "   0.158792270531401,\n",
       "   0.10926500481437887]]}"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "final_result['portfolio_wght']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_timeseries['prc'].fillna(method='bfill',inplace=True)\n",
    "port_rtn = (my_timeseries['prc'].iloc[-1] / my_timeseries['prc'].iloc[0] - 1)\n",
    "final_result['portfolio_anal']['label'] = port_rtn.index.tolist()\n",
    "final_result['portfolio_anal']['dataset'] = port_rtn.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'label': ['069500', '261220', '332940', '371450', 'HERO', 'SPY'],\n",
       " 'dataset': [0.3935646769390133,\n",
       "  -0.5716678631251495,\n",
       "  0.7341708542713568,\n",
       "  0.061316051844466646,\n",
       "  1.182967398536261,\n",
       "  0.5310116456449754]}"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "final_result['portfolio_anal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             069500   261220   332940   371450   HERO     SPY\n",
       "DATE                                                         \n",
       "2018-01-02  30892.0  20895.0      NaN      NaN    NaN  268.77\n",
       "2018-01-03  31023.0  20770.0      NaN      NaN    NaN  270.47\n",
       "2018-01-04  30780.0  21380.0      NaN      NaN    NaN  271.61\n",
       "2018-01-05  31197.0  21320.0      NaN      NaN    NaN  273.42\n",
       "2018-01-08  31408.0  21180.0      NaN      NaN    NaN  273.92\n",
       "...             ...      ...      ...      ...    ...     ...\n",
       "2021-04-05  43130.0   9095.0  17390.0  10600.0  32.49  406.36\n",
       "2021-04-06  43190.0   8945.0  17430.0  10550.0  32.58  406.12\n",
       "2021-04-07  43295.0   8925.0  17455.0  10590.0  32.41  406.59\n",
       "2021-04-08  43255.0   8890.0  17375.0  10575.0  32.87  408.52\n",
       "2021-04-09  43050.0   8950.0  17255.0  10645.0  32.81  411.49\n",
       "\n",
       "[848 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>069500</th>\n      <th>261220</th>\n      <th>332940</th>\n      <th>371450</th>\n      <th>HERO</th>\n      <th>SPY</th>\n    </tr>\n    <tr>\n      <th>DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-02</th>\n      <td>30892.0</td>\n      <td>20895.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>268.77</td>\n    </tr>\n    <tr>\n      <th>2018-01-03</th>\n      <td>31023.0</td>\n      <td>20770.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>270.47</td>\n    </tr>\n    <tr>\n      <th>2018-01-04</th>\n      <td>30780.0</td>\n      <td>21380.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>271.61</td>\n    </tr>\n    <tr>\n      <th>2018-01-05</th>\n      <td>31197.0</td>\n      <td>21320.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>273.42</td>\n    </tr>\n    <tr>\n      <th>2018-01-08</th>\n      <td>31408.0</td>\n      <td>21180.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>273.92</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-04-05</th>\n      <td>43130.0</td>\n      <td>9095.0</td>\n      <td>17390.0</td>\n      <td>10600.0</td>\n      <td>32.49</td>\n      <td>406.36</td>\n    </tr>\n    <tr>\n      <th>2021-04-06</th>\n      <td>43190.0</td>\n      <td>8945.0</td>\n      <td>17430.0</td>\n      <td>10550.0</td>\n      <td>32.58</td>\n      <td>406.12</td>\n    </tr>\n    <tr>\n      <th>2021-04-07</th>\n      <td>43295.0</td>\n      <td>8925.0</td>\n      <td>17455.0</td>\n      <td>10590.0</td>\n      <td>32.41</td>\n      <td>406.59</td>\n    </tr>\n    <tr>\n      <th>2021-04-08</th>\n      <td>43255.0</td>\n      <td>8890.0</td>\n      <td>17375.0</td>\n      <td>10575.0</td>\n      <td>32.87</td>\n      <td>408.52</td>\n    </tr>\n    <tr>\n      <th>2021-04-09</th>\n      <td>43050.0</td>\n      <td>8950.0</td>\n      <td>17255.0</td>\n      <td>10645.0</td>\n      <td>32.81</td>\n      <td>411.49</td>\n    </tr>\n  </tbody>\n</table>\n<p>848 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "my_timeseries['prc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.diff(y, axis=0)\n",
    "a = z.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.2626955509185791,\n",
       " 0.036902427673339844,\n",
       " 0.03091597557067871,\n",
       " 0.03690838813781738]"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['시작', '테스트데이터 로드', '시계열 데이터 전처리', '지수산출', '시계열분석'], dtype='<U18')"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['시작', '테스트데이터 로드', '시계열 데이터 전처리', '지수산출', '시계열분석',\n",
       "       '1620706190.354424', '1620706190.6171196', '1620706190.654022',\n",
       "       '1620706190.684938', '1620706190.7218463'], dtype='<U32')"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "np.concatenate((z,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2626955509185791\n0.036902427673339844\n0.03091597557067871\n0.03690838813781738\n"
     ]
    }
   ],
   "source": [
    "for x in np.nditer(z):\n",
    "    print( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0eb2ea88378ba9cae9857dcdd71e952e501ce699f1db322a6913609a7ff7b9c0b",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}